# -*- coding: utf-8 -*-
"""
Module Face Detection vÃ  Recognition sá»­ dá»¥ng MTCNN vÃ  FaceNet
Face Detection & Recognition Module using MTCNN and FaceNet
"""

import cv2
import numpy as np
import torch
from PIL import Image
from facenet_pytorch import MTCNN, InceptionResnetV1
import config
import pymongo

#Káº¿t ná»‘i MongoDB
client = pymongo.MongoClient("mongodb://localhost:27017/")
db = client["face_db"]
col = db["faces"]

class FaceRecognizer:
    def delete_all_employees(self):
        """XÃ³a toÃ n bá»™ dá»¯ liá»‡u nhÃ¢n viÃªn khá»i RAM vÃ  MongoDB"""
        self.known_embeddings = {}
        self.known_names = {}
        col.delete_many({})
        print("ÄÃ£ xÃ³a toÃ n bá»™ dá»¯ liá»‡u nhÃ¢n viÃªn khá»i há»‡ thá»‘ng.")
    def delete_employee(self, employee_id):
        """XÃ³a dá»¯ liá»‡u nhÃ¢n viÃªn khá»i RAM vÃ  MongoDB"""
        # XÃ³a khá»i RAM
        if employee_id in self.known_embeddings:
            del self.known_embeddings[employee_id]
        if employee_id in self.known_names:
            del self.known_names[employee_id]
        # XÃ³a trÃªn MongoDB
        col.delete_one({"employee_id": employee_id})
        print(f"ÄÃ£ xÃ³a nhÃ¢n viÃªn {employee_id} khá»i há»‡ thá»‘ng.")
    """Class nháº­n diá»‡n khuÃ´n máº·t sá»­ dá»¥ng MTCNN vÃ  FaceNet"""
    
    def __init__(self):
        """Khá»Ÿi táº¡o MTCNN vÃ  FaceNet model"""
        # Kiá»ƒm tra GPU
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ðŸ–¥ï¸  Using device: {self.device}")
        
        # Khá»Ÿi táº¡o MTCNN cho face detection
        self.mtcnn = MTCNN(
            image_size=config.FACENET_IMAGE_SIZE,
            margin=0,
            min_face_size=config.MTCNN_MIN_FACE_SIZE,
            thresholds=config.MTCNN_THRESHOLDS,
            factor=config.MTCNN_FACTOR,
            post_process=True,
            device=self.device,
            keep_all=True  # Detect táº¥t cáº£ khuÃ´n máº·t trong áº£nh
        )
        
        # Khá»Ÿi táº¡o FaceNet (InceptionResnetV1) Ä‘á»ƒ extract embeddings
        print("â³ Loading FaceNet model...")
        self.facenet = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)
        print("âœ… FaceNet model loaded successfully!")
        
        # Dictionary lÆ°u face embeddings
        self.known_embeddings = {}
        self.known_names = {} 

    def save_face_to_mongodb(self, employee_id, name, embedding):
        doc = {
            "employee_id": employee_id,
            "name": name,
            "embedding": embedding.tolist()  # numpy array -> list
        }
        col.replace_one({"employee_id": employee_id}, doc, upsert=True)
        print(f"ÄÃ£ lÆ°u khuÃ´n máº·t {name} vÃ o MongoDB.")

    def load_all_embeddings_from_mongodb(self):
        faces = list(col.find({}))
        self.known_embeddings = {f["employee_id"]: np.array(f["embedding"]) for f in faces}
        self.known_names = {f["employee_id"]: f["name"] for f in faces}
        print(f"ÄÃ£ táº£i {len(self.known_embeddings)} khuÃ´n máº·t tá»« MongoDB.")
    def detect_faces(self, image):
        """
        PhÃ¡t hiá»‡n khuÃ´n máº·t trong áº£nh sá»­ dá»¥ng MTCNN
        
        Args:
            image: numpy array (BGR format from OpenCV)
        
        Returns:
            faces: List of face tensors
            boxes: List of bounding boxes [x1, y1, x2, y2]
            probs: List of confidence scores
        """
        # Convert BGR to RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Detect faces
        boxes, probs, landmarks = self.mtcnn.detect(image_rgb, landmarks=True)
        
        if boxes is None:
            return None, None, None, None
        
        # Filter faces with confidence > threshold
        valid_indices = probs > config.MIN_CONFIDENCE
        boxes = boxes[valid_indices]
        probs = probs[valid_indices]
        
        if landmarks is not None:
            landmarks = landmarks[valid_indices]
        
        if len(boxes) == 0:
            return None, None, None, None
        
        # Extract and align faces
        faces = []
        for box in boxes:
            x1, y1, x2, y2 = [int(b) for b in box]
            
            # Kiá»ƒm tra box há»£p lá»‡
            if x2 <= x1 or y2 <= y1:
                continue
                
            face = image_rgb[y1:y2, x1:x2]
            
            # Kiá»ƒm tra face khÃ´ng rá»—ng
            if face.size == 0 or face.shape[0] == 0 or face.shape[1] == 0:
                continue
            
            # Resize to FaceNet input size
            face = cv2.resize(face, (config.FACENET_IMAGE_SIZE, config.FACENET_IMAGE_SIZE))
            faces.append(face)
        
        return faces, boxes, probs, landmarks
    
    def get_embedding(self, face_image):
        """
        TrÃ­ch xuáº¥t face embedding tá»« áº£nh khuÃ´n máº·t
        
        Args:
            face_image: numpy array (RGB format)
        
        Returns:
            embedding: 512-dimensional vector
        """
        # Convert to tensor
        face_tensor = torch.from_numpy(face_image).permute(2, 0, 1).float()
        face_tensor = (face_tensor - 127.5) / 128.0  # Normalize
        face_tensor = face_tensor.unsqueeze(0).to(self.device)
        
        # Get embedding
        with torch.no_grad():
            embedding = self.facenet(face_tensor)
        
        return embedding.cpu().numpy()[0]
    
    def register_face(self, employee_id, name, face_images):
        """
        ÄÄƒng kÃ½ khuÃ´n máº·t má»›i
        
        Args:
            employee_id: ID nhÃ¢n viÃªn
            name: TÃªn nhÃ¢n viÃªn
            face_images: List cÃ¡c áº£nh khuÃ´n máº·t (RGB format)
        
        Returns:
            success: True náº¿u Ä‘Äƒng kÃ½ thÃ nh cÃ´ng
        """
        embeddings = []
        
        for face_image in face_images:
            embedding = self.get_embedding(face_image)
            embeddings.append(embedding)
        
        # TÃ­nh embedding trung bÃ¬nh
        avg_embedding = np.mean(embeddings, axis=0)
        #LÆ°u vÃ o MongoDB
        self.save_face_to_mongodb(employee_id, name, avg_embedding)
        # LÆ°u vÃ o dictionary
        self.known_embeddings[employee_id] = avg_embedding
        self.known_names[employee_id] = name
        
        print(f"âœ… Registered face for {name} (ID: {employee_id})")
        return True
    
    def recognize_face(self, face_image):
        """
        Nháº­n diá»‡n khuÃ´n máº·t
        
        Args:
            face_image: numpy array (RGB format)
        
        Returns:
            employee_id: ID cá»§a nhÃ¢n viÃªn (hoáº·c None)
            name: TÃªn nhÃ¢n viÃªn (hoáº·c "Unknown")
            distance: Khoáº£ng cÃ¡ch Euclidean
        """
        if len(self.known_embeddings) == 0:
            return None, "Unknown", 1.0
        
        # Get embedding cá»§a khuÃ´n máº·t cáº§n nháº­n diá»‡n
        embedding = self.get_embedding(face_image)
        
        # So sÃ¡nh vá»›i táº¥t cáº£ embeddings Ä‘Ã£ lÆ°u
        min_distance = float('inf')
        best_match_id = None
        
        for employee_id, known_embedding in self.known_embeddings.items():
            # TÃ­nh Euclidean distance
            distance = np.linalg.norm(embedding - known_embedding)
            
            if distance < min_distance:
                min_distance = distance
                best_match_id = employee_id
        
        # Kiá»ƒm tra threshold
        if min_distance < config.FACE_RECOGNITION_THRESHOLD:
            name = self.known_names.get(best_match_id, "Unknown")
            return best_match_id, name, min_distance
        else:
            return None, "Unknown", min_distance
    
    def load_embeddings(self, embeddings_dict):
        """Load face embeddings tá»« database"""
        self.known_embeddings = embeddings_dict.get('embeddings', {})
        self.known_names = embeddings_dict.get('names', {})
        print(f"âœ… Loaded {len(self.known_embeddings)} face embeddings")
    
    def save_embeddings(self):
        """LÆ°u face embeddings"""
        return {
            'embeddings': self.known_embeddings,
            'names': self.known_names
        }
    
    def draw_detections(self, image, boxes, names, probs):
        """
        Váº½ bounding boxes vÃ  tÃªn lÃªn áº£nh
        
        Args:
            image: numpy array (BGR)
            boxes: List of bounding boxes
            names: List of names
            probs: List of confidence scores
        
        Returns:
            image: áº¢nh Ä‘Ã£ váº½ annotations
        """
        image_draw = image.copy()
        
        for i, box in enumerate(boxes):
            x1, y1, x2, y2 = [int(b) for b in box]
            name = names[i] if i < len(names) else "Unknown"
            prob = probs[i] if i < len(probs) else 0.0
            
            # Chá»n mÃ u
            color = (0, 255, 0) if name != "Unknown" else (0, 0, 255)
            
            # Váº½ bounding box
            cv2.rectangle(image_draw, (x1, y1), (x2, y2), color, 2)
            
            # Váº½ label
            label = f"{name} ({prob:.2f})"
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(image_draw, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            cv2.putText(image_draw, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return image_draw

    def clear_memory(self):
        """XÃ³a toÃ n bá»™ dá»¯ liá»‡u khuÃ´n máº·t trong RAM"""
        self.known_embeddings = {}
        self.known_names = {}
        print("ÄÃ£ xÃ³a toÃ n bá»™ dá»¯ liá»‡u khuÃ´n máº·t trong RAM.")


# Test module
if __name__ == "__main__":
    print("ðŸ§ª Testing Face Recognition Module...")
    
    # Khá»Ÿi táº¡o
    recognizer = FaceRecognizer()
    # XÃ³a toÃ n bá»™ dá»¯ liá»‡u nhÃ¢n viÃªn khá»i RAM vÃ  MongoDB
    recognizer.delete_all_employees()
    print("ÄÃ£ xÃ³a sáº¡ch toÃ n bá»™ dá»¯ liá»‡u nhÃ¢n viÃªn!")
    
    # Test vá»›i webcam
    cap = cv2.VideoCapture(config.CAMERA_INDEX)
    
    print("ðŸ“¹ Press 'q' to quit")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame = cv2.flip(frame, -1)
        faces, boxes, probs, landmarks = recognizer.detect_faces(frame)
        
        if boxes is not None:
            # Draw detections
            names = ["Unknown"] * len(boxes)
            frame = recognizer.draw_detections(frame, boxes, names, probs)
        
        # Display
        cv2.imshow('Face Detection Test', frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("âœ… Test completed!")
  